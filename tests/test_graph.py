import pandas as pd
import numpy as np
import os
from typing import List

base_dir = r"C:\Users\rodyh\Desktop\FairOnChain\Code\whale-anomaly-detector-faironchain\data\output\graph\ethereum\2023\02"
file1 = os.path.join(base_dir, "ethereum__features__2023_02_0.csv")  # èˆŠå‘½åç‰ˆ
file2 = os.path.join(base_dir, "ethereum__features__2023_02.csv")    # æ–°å‘½åç‰ˆ

# è‡ªå‹•æ‰¾å°é½Šéµ
CANDIDATE_KEYS: List[str] = ["node","node_id","account_sid","address","vertex_id","id"]
def pick_key(p1, p2, candidates):
    c1 = set(pd.read_csv(p1, nrows=0).columns)
    c2 = set(pd.read_csv(p2, nrows=0).columns)
    for k in candidates:
        if k in c1 and k in c2:
            return k
    raise RuntimeError("æ‰¾ä¸åˆ°å…±åŒéµæ¬„ä½ï¼Œè«‹ç¢ºèªå…©æª”å…±æœ‰çš„å”¯ä¸€IDï¼ˆå¦‚ nodeï¼‰ã€‚")

key = pick_key(file1, file2, CANDIDATE_KEYS)
print(f"âˆš å°é½Šéµï¼š{key}")

# è®€å®Œæ•´æ¬„ä½
df_old = pd.read_csv(file1)
df_new = pd.read_csv(file2)

# å…ˆå»é‡
df_old = df_old.drop_duplicates(subset=[key])
df_new = df_new.drop_duplicates(subset=[key])

# é‡å°èˆŠæª” â†’ æ–°æª”çš„æ¬„ä½å°é½Šï¼ˆä½ èªªçš„å°æ‡‰é—œä¿‚ï¼‰
rename_map = {
    "in_degree": "in_transfer_count",
    "out_degree": "out_transfer_count",
    "unique_in_degree": "in_degree",
    "unique_out_degree": "out_degree",
}
# åªæ”¹èˆŠæª”æ¬„ä½å
df_old = df_old.rename(columns={k:v for k,v in rename_map.items() if k in df_old.columns})

# åªæ¯”å…±åŒéµçš„äº¤é›†åˆ—ï¼Œé¿å… NaN å¹²æ“¾
both = set(df_old[key]) & set(df_new[key])
df_old = df_old[df_old[key].isin(both)].set_index(key).sort_index()
df_new = df_new[df_new[key].isin(both)].set_index(key).sort_index()

# æ¬„ä½é›†åˆå°é½Šï¼ˆç¼ºèª°å°±è£œèª°ç‚º NaNï¼‰ï¼Œç¢ºä¿èƒ½é€æ ¼æ¯”è¼ƒ
all_cols = sorted(set(df_old.columns) | set(df_new.columns))
for c in all_cols:
    if c not in df_old.columns:
        df_old[c] = np.nan
    if c not in df_new.columns:
        df_new[c] = np.nan

df_old = df_old[all_cols]
df_new = df_new[all_cols]

# å‹åˆ¥å¯¬é¬†çµ±ä¸€ï¼ˆæŠŠèƒ½è½‰æ•¸å€¼çš„éƒ½è½‰æ•¸å€¼ï¼Œå…¶ä»–ä¿æŒå­—ä¸²ï¼‰ï¼Œé¿å… '1' vs 1 çš„å‡å·®ç•°
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    for c in out.columns:
        # å˜—è©¦è½‰æ•¸å€¼ï¼›å…¨ NaN å°±ç¶­æŒåŸç‹€
        s = pd.to_numeric(out[c], errors="coerce")
        if s.notna().sum() > 0 or out[c].isna().all():
            out[c] = s
        else:
            out[c] = out[c].astype(str)
    return out

df_old_n = normalize_df(df_old)
df_new_n = normalize_df(df_new)

# å…ˆç”¨ equals å¿«é€Ÿæª¢æŸ¥
if df_old_n.equals(df_new_n):
    print("ğŸ‰ å…©æª”å…§å®¹åœ¨å°é½Šå‘½åå¾Œå®Œå…¨ä¸€è‡´ï¼ˆå« NaN ä½ç½®èˆ‡æ‰€æœ‰æ¬„ä½ï¼‰")
else:
    print("âš ï¸ ç™¼ç¾å·®ç•°ï¼Œçµ±è¨ˆå¦‚ä¸‹ï¼š")
    diff_mask = (df_old_n != df_new_n) & ~(df_old_n.isna() & df_new_n.isna())
    total_diff = int(diff_mask.to_numpy().sum())
    row_diff = int(diff_mask.any(axis=1).sum())
    col_diff = int(diff_mask.any(axis=0).sum())
    print(f"- ä¸åŒçš„å„²å­˜æ ¼æ•¸ï¼š{total_diff:,}")
    print(f"- æ¶‰åŠçš„åˆ—æ•¸é‡ï¼š{row_diff:,}")
    print(f"- æ¶‰åŠçš„æ¬„ä½æ•¸é‡ï¼š{col_diff:,}")

    # å„æ¬„ä½ä¸ä¸€è‡´æ•¸
    print("\nå„æ¬„ä½ä¸ä¸€è‡´æ•¸ï¼š")
    per_col = diff_mask.sum(axis=0).sort_values(ascending=False)
    print(per_col[per_col > 0].to_string())

    # åˆ—å‡ºå‰ 10 åˆ—å·®ç•°ï¼ˆé™„å…©é‚Šå€¼ï¼‰
    preview = pd.concat(
        [df_old_n[diff_mask.any(axis=1)].add_suffix("_old"),
         df_new_n[diff_mask.any(axis=1)].add_suffix("_new")],
        axis=1
    ).reset_index().head(10)
    print("\nå‰ 10 ç­†å·®ç•°ï¼š")
    print(preview.to_string(index=False))

    # å¯é¸ï¼šè¼¸å‡ºå®Œæ•´å·®ç•°é è¦½
    preview.to_csv(os.path.join(base_dir, "diff_preview_after_rename.csv"), index=False)
